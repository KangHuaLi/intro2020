<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision | Cheng-Che Lee (SunnerLi)</title>
    <link>https://KangHuaLi.github.io/intro2020/tags/computer-vision/</link>
      <atom:link href="https://KangHuaLi.github.io/intro2020/tags/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    <description>Computer Vision</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 01 Mar 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://KangHuaLi.github.io/intro2020/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Computer Vision</title>
      <link>https://KangHuaLi.github.io/intro2020/tags/computer-vision/</link>
    </image>
    
    <item>
      <title>Anoymous Title</title>
      <link>https://KangHuaLi.github.io/intro2020/publication/chiu2019/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://KangHuaLi.github.io/intro2020/publication/chiu2019/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&#39;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>StyleGAN demo</title>
      <link>https://KangHuaLi.github.io/intro2020/project/stylegan_demo/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://KangHuaLi.github.io/intro2020/project/stylegan_demo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Simple Smartphone-Based Guiding System for Visually Impaired People</title>
      <link>https://KangHuaLi.github.io/intro2020/publication/lin2017/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      <guid>https://KangHuaLi.github.io/intro2020/publication/lin2017/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&#39;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>DeepFuse.pytorch</title>
      <link>https://KangHuaLi.github.io/intro2020/project/deepfuse.pytorch/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://KangHuaLi.github.io/intro2020/project/deepfuse.pytorch/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Easy-Guide</title>
      <link>https://KangHuaLi.github.io/intro2020/project/easy-guide/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://KangHuaLi.github.io/intro2020/project/easy-guide/</guid>
      <description>&lt;p&gt;This is the graduate project of our college. This system can serve the people that tell them what it is in front of the road. The user can open the app and hold it toward the front. At the same time, the phone would try to connect to the server. The phone would keep catching the image of the front, and send to the server. Next, the server would use image processing algorithm to recognize the distance, direction and type of the obstacle. At last, the result would be sent back and tell the user.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GANomaly2D</title>
      <link>https://KangHuaLi.github.io/intro2020/project/ganomaly2d/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://KangHuaLi.github.io/intro2020/project/ganomaly2d/</guid>
      <description></description>
    </item>
    
    <item>
      <title>P-Conv</title>
      <link>https://KangHuaLi.github.io/intro2020/project/p-conv/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://KangHuaLi.github.io/intro2020/project/p-conv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RecycleGAN</title>
      <link>https://KangHuaLi.github.io/intro2020/project/recyclegan/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://KangHuaLi.github.io/intro2020/project/recyclegan/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
